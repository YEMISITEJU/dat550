{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eqrIvLMQHxh"
   },
   "source": [
    " This notebook trains a Siamese network to discriminate deep fake images from original images\n",
    "\n",
    " Subsections\n",
    "\n",
    "* Loading the dataset\n",
    "* Preprocessing the data\n",
    "* Compile Siamese Network\n",
    "* Train the Network\n",
    "* Evaluate the Network\n",
    "\n",
    "\n",
    "Dataset used: Sample test videos and train sample videos (4.44 GB)\n",
    "Google Drive link: https://drive.google.com/drive/folders/188tAIRLAuNgnH31DVbBvzrlpfROhW2Se?usp=sharing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW4UXQ3bRRIp"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbZ6T9SnSNK1",
    "outputId": "ac37b0fd-1f71-455b-bc22-441483ad5712"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Mount Google Drive\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[1;32m      3\u001B[0m drive\u001B[38;5;241m.\u001B[39mflush_and_unmount()\n\u001B[1;32m      4\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqFuUsOYQEN2"
   },
   "outputs": [],
   "source": [
    "from matplotlib import path\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path as path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet, vgg16\n",
    "from tensorflow.keras import Model, models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Max1X-e_TB9t"
   },
   "outputs": [],
   "source": [
    "# Set constants and hyper parameters\n",
    "# Change the embedding model here\n",
    "embedding_model_choice = \"vgg\"\n",
    "cosine_similarity = metrics.CosineSimilarity()\n",
    "target_shape = (224, 224) if embedding_model_choice == \"vgg\" else (200, 200)\n",
    "\n",
    "cache_dir = path(path.home()) / \".siamese_images\"\n",
    "anchor_images_path = cache_dir / \"real_imgs\"\n",
    "negative_images_path = cache_dir / \"fake_imgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSuDanvoT5DX",
    "outputId": "b240fa91-be39-49c7-e973-2d847370d7b7"
   },
   "outputs": [],
   "source": [
    "# Download dataset from Google Drive\n",
    "!gdown --id 1jvkbTr_giSP3Ru8OwGNCg6B4PvVbcO34\n",
    "!gdown --id 1EzBZUb_mh_Dp_FKD0P4XiYYSd0QBH5zW\n",
    "!unzip -oq /content/drive/MyDrive/datamining/large/real_imgs.zip -d $cache_dir\n",
    "!unzip -oq /content/drive/MyDrive/datamining/large/fake_imgs.zip -d $cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx3Vo5RZaOfV"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOn94A7rUxFy"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_image(file_name:str):\n",
    "  \"\"\"\n",
    "  Load image from the file (JPEG), preprocess and resize to target shape\n",
    "  \"\"\"\n",
    "  image = tf.io.read_file(file_name) \n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  return tf.image.resize(image, target_shape)\n",
    "\n",
    "\n",
    "def preprocess_triplets(\n",
    "    anchor_image:str, \n",
    "    positive_image:str,\n",
    "     negative_image:str\n",
    "     ):\n",
    "  \"\"\"\n",
    "  Load and preprocess anchor, positive and negative iamges\n",
    "  \"\"\"\n",
    "  return (\n",
    "      load_preprocess_image(anchor_image),\n",
    "      load_preprocess_image(positive_image),\n",
    "      load_preprocess_image(negative_image)\n",
    "  )\n",
    "\n",
    "def load_preprocess_train_image(file_name:str, label:str):\n",
    "  \"\"\"\n",
    "  Load image from the file (JPEG), preprocess and resize to target shape\n",
    "  \"\"\"\n",
    "  image = tf.io.read_file(file_name) \n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  return tf.image.resize(image, target_shape), label\n",
    "\n",
    "def preprocess_pairs(\n",
    "    anchor_image:str, \n",
    "     negative_image:str\n",
    "     ):\n",
    "  \"\"\"\n",
    "  Load and preprocess anchor, positive and negative iamges\n",
    "  \"\"\"\n",
    "  return (\n",
    "      load_preprocess_train_image(anchor_image),\n",
    "      load_preprocess_train_image(negative_image)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "nXgO4r-RZRYo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8QikBfqZW28"
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data():\n",
    "  \"\"\"\n",
    "  Collect images from test data for preprocessing\n",
    "  Returns: validation dataset, training dataset\n",
    "  \"\"\"\n",
    "  # Collect all images filenames\n",
    "  anchor_images = [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n",
    "  negative_images = [str(negative_images_path / f) for f in os.listdir(negative_images_path)]\n",
    "  positive_images = [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n",
    "  np.random.RandomState(seed=32).shuffle(positive_images)\n",
    "\n",
    "\n",
    "  # Create Datasets\n",
    "  anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "  positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "  negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "\n",
    "  # Preprocess pipeline\n",
    "  dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "  dataset = dataset.shuffle(buffer_size=256)\n",
    "  dataset = dataset.map(preprocess_triplets)\n",
    "\n",
    "  image_count = len(anchor_images)\n",
    "  train_dataset = dataset.take(round(image_count * 0.5))\n",
    "  val_dataset = dataset.skip(round(image_count * 0.8))\n",
    "  test_dataset = dataset.skip(round(image_count * 0.5))\n",
    "\n",
    "  return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Su-opqxfWTW"
   },
   "source": [
    "Visualize some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmh0tzULfRGW"
   },
   "outputs": [],
   "source": [
    "def visualize(anchor, positive, negative):\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    axs = fig.subplots(3, 3)\n",
    "    for i in range(3):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj3Mt7uOgEgc"
   },
   "source": [
    "# Building the Model\n",
    "## Encoding Features\n",
    "We are experimenting with two models\n",
    "\n",
    "\n",
    "*   Resnet\n",
    "*   Vgg16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x26D8HP6f5HY"
   },
   "outputs": [],
   "source": [
    "def get_embedding_model(model_name:str):\n",
    "  # vgg16\n",
    "  if model_name == \"vgg\":\n",
    "    vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = target_shape + (3,))\n",
    "    for layer in vgg_conv.layers[:-1]:\n",
    "      layer.trainable = False\n",
    "    flatten = layers.Flatten()(vgg_conv.output)\n",
    "    dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "    dense1 = layers.BatchNormalization()(dense1)\n",
    "    dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "    dense2 = layers.BatchNormalization()(dense2)\n",
    "    output = layers.Dense(128)(dense2)\n",
    "    embedding = Model(vgg_conv.input, output, name=\"Embedding\")\n",
    "  # res50\n",
    "  if model_name == \"res50\":\n",
    "    resnet_conv = resnet.ResNet50(\n",
    "        weights = \"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    "    )\n",
    "    flatten = layers.Flatten()(resnet_conv.layers[-1].output)\n",
    "    dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "    dense1 = layers.BatchNormalization()(dense1)\n",
    "    dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "    dense2 = layers.BatchNormalization()(dense2)\n",
    "    output = layers.Dense(128)(dense2)\n",
    "    embedding = Model(resnet_conv.input, output, name=\"Embedding\")\n",
    "\n",
    "  #Xception\n",
    "  return embedding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXNNyqCGPbYd"
   },
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom layer that returns the distances, the distances are used to calculate loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "class ComparisonLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ComparisonLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ap, an = inputs\n",
    "        # Compute the difference between the two distances\n",
    "        output = tf.math.greater(\n",
    "            an, ap, name=None\n",
    "        )\n",
    "        # Compare the difference to zero\n",
    "        # output = K.cast(K.greater(diff, 0), dtype='float32')\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # The output shape is a scalar\n",
    "        return (1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Patching up the Siamese network"
   ],
   "metadata": {
    "id": "46LRZ_ex6siv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "\n",
    "embedding_model = get_embedding_model(embedding_model_choice)\n",
    "\n",
    "\n",
    "if embedding_model_choice == \"vgg\":\n",
    "  distances = DistanceLayer()(\n",
    "      embedding_model(vgg16.preprocess_input(anchor_input)),\n",
    "      embedding_model(vgg16.preprocess_input(positive_input)),\n",
    "      embedding_model(vgg16.preprocess_input(negative_input)),\n",
    "  )\n",
    "else:\n",
    "  distances = DistanceLayer()(\n",
    "      embedding_model(resnet.preprocess_input(anchor_input)),\n",
    "      embedding_model(resnet.preprocess_input(positive_input)),\n",
    "      embedding_model(resnet.preprocess_input(negative_input)),\n",
    "  )\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")\n"
   ],
   "metadata": {
    "id": "lP5dp3HK60Yk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEPLyv6uS7zq",
    "outputId": "cc997c06-fd0c-49d3-a1f2-860396ce784f"
   },
   "outputs": [],
   "source": [
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xig7n75BRoZ1"
   },
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "        # Update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        # Update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "        # Computing the Triplet Loss \n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    def classiffy(self, data):\n",
    "        ap, an = self.siamese_network.predict(data)\n",
    "        output = tf.math.greater(\n",
    "            an, ap, name=None\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPh_RutoPp7P",
    "outputId": "7a6e9b5b-862c-4d46-c849-1dab308da414"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = preprocess_training_data()\n",
    "\n",
    "train_dataset = train_dataset.batch(16, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(16, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=optimizer)\n",
    "siamese_model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# siamese_model.save('content/drive/MyDrive/datamining/', save_format='tf')\n",
    "# siamese_model.save_weights('content/drive/MyDrive/datamining/ckpt')"
   ],
   "metadata": {
    "id": "-mmWldBWoEvr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model from weights\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.load_weights(\"content/drive/MyDrive/datamining/ckpt\")"
   ],
   "metadata": {
    "id": "IP53eSn93t8Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the model\n",
    "ap should be greater than an"
   ],
   "metadata": {
    "id": "I3mLMLWN-i8U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sample = next(iter(train_dataset))\n",
    "visualize(*sample)\n",
    "\n",
    "anchor, positive, negative = sample\n",
    "anchor_embedding, positive_embedding, negative_embedding = (\n",
    "    embedding_model(vgg16.preprocess_input(anchor)),\n",
    "    embedding_model(vgg16.preprocess_input(positive)),\n",
    "    embedding_model(vgg16.preprocess_input(negative)),\n",
    ")\n",
    "\n",
    "positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "print(\"Negative similarity\", negative_similarity.numpy())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "PNptQRTVfo1M",
    "outputId": "bd12bd67-3d65-4f04-a61b-455e57245896"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cosine_similarity = metrics.CosineSimilarity()\n",
    "positive_similarity = []\n",
    "negative_similarity= []\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = preprocess_training_data()\n",
    "test_dataset = test_dataset.batch(8, drop_remainder=False)\n",
    "test_dataset = test_dataset.prefetch(8)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.batch(8, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "for x,y,z in iter(train_dataset):\n",
    "  anchor_embedding = embedding_model(vgg16.preprocess_input(x))\n",
    "  positive_embedding = embedding_model(vgg16.preprocess_input(y))\n",
    "  negative_embedding = embedding_model(vgg16.preprocess_input(z))\n",
    "\n",
    "  positive_similarity.append(cosine_similarity(anchor_embedding, positive_embedding).numpy())\n",
    "  negative_similarity.append(cosine_similarity(anchor_embedding, negative_embedding).numpy())\n"
   ],
   "metadata": {
    "id": "6kmC6PdU5wZx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check the training accuracy by checking the no of time negative similarity is larger than positive similarity\n",
    "\n",
    "falses = 0\n",
    "for i in range(len(negative_similarity)):\n",
    "  if negative_similarity[i] > positive_similarity[i]:\n",
    "      falses+=1"
   ],
   "metadata": {
    "id": "bAUdKGoe7oRF"
   },
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'negative_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m falses \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mnegative_similarity\u001B[49m)):\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m negative_similarity[i] \u001B[38;5;241m>\u001B[39m positive_similarity[i]:\n\u001B[1;32m      4\u001B[0m       falses\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'negative_similarity' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "(len(negative_similarity)- falses)/len(negative_similarity)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dfbmSGXXZd2",
    "outputId": "97a240e7-0d4c-4c19-e6b7-6975e2f2e872"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnNBnrH9fjaA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a3e3a7d-15d4-4071-a7b0-832ffbbe1392"
   },
   "outputs": [],
   "source": [
    "cosine_similarity = metrics.CosineSimilarity()\n",
    "\n",
    "positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "print(\"Negative similarity\", negative_similarity.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Plot the negative similarities and positive similarities to visualize the distribution\n",
    "\n",
    "plt.hist(positive_similarity, bins=50, label='Positive')\n",
    "plt.hist(negative_similarity, bins=50, label='Negative')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "JYBROx2K5Zno",
    "outputId": "a8e2ad41-5158-48d4-daca-4b52e24759ca"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Images to compare new images with\n",
    "negative_images = [str(negative_images_path / f) for f in os.listdir(negative_images_path)]\n",
    "positive_images = [str(anchor_images_path / f) for f in os.listdir(anchor_images_path)]\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def classify_video(face_paths):\n",
    "  # Prepare facess\n",
    "  faces_dataset = tf.data.Dataset.from_tensor_slices(face_paths)\n",
    "    # Preprocess pipeline\n",
    "  dataset = tf.data.Dataset.zip((faces_dataset, positive_dataset, negative_dataset))\n",
    "  # dataset = dataset.shuffle(buffer_size=256)\n",
    "  dataset = dataset.map(preprocess_triplets)\n",
    "  dataset = dataset.batch(32, drop_remainder=False)\n",
    "  dataset = dataset.prefetch(8)\n",
    "  positives = []\n",
    "  negatives = []\n",
    "  samples = iter(dataset)\n",
    "  for sample in samples:\n",
    "    x,y,z  = sample\n",
    "    face_embedding = embedding_model(vgg16.preprocess_input(x))\n",
    "    positive_embedding = embedding_model(vgg16.preprocess_input(y))\n",
    "    negative_embedding = embedding_model(vgg16.preprocess_input(z))\n",
    "\n",
    "    positive_similarity = cosine_similarity(face_embedding, positive_embedding)\n",
    "    negative_similarity = cosine_similarity(face_embedding, negative_embedding)\n",
    "    if positive_similarity > negative_similarity:\n",
    "      positives.append(positive_similarity.numpy())\n",
    "    else:\n",
    "      negatives.append(negative_similarity.numpy())\n",
    "    # sample = next(iter(train_dataset))\n",
    "\n",
    "  print(len(positives) ,len(negatives))\n",
    "  # return positives, negatives\n",
    "  return \"Real\" if len(positives) > len(negatives) else \"Fake\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MtiKH1_Zh_g",
    "outputId": "5d577075-57b1-44dd-d378-6d77615f28e9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "LmCpAx5x_PkL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}